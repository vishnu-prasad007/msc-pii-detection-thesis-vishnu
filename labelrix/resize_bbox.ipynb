{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4309995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_preds_dir = \"/Volumes/MyDataDrive/thesis/code-2/src/weak-labels-algo/AD_BUY_AUTO_LABELS/Qwen2.5-72B-Instruct-per_page_votes_merged\"\n",
    "images_dir = \"/Volumes/MyDataDrive/thesis/code-2/src/labelrix/ad-buy-form/test-images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "try:\n",
    "\tfrom PIL import Image\n",
    "except ImportError as e:\n",
    "\traise ImportError(\"Pillow is required: pip install pillow\") from e\n",
    "\n",
    "\n",
    "def _derive_image_filename_from_json(json_filename: str) -> str:\n",
    "\t\"\"\"Map a predictions JSON filename to its corresponding image filename.\n",
    "\n",
    "\tExample: votes_<doc>.pdf_page1.json -> <doc>_page1.png\n",
    "\t\"\"\"\n",
    "\tname = os.path.splitext(os.path.basename(json_filename))[0]\n",
    "\tif name.startswith(\"votes_\"):\n",
    "\t\tname = name[len(\"votes_\"):]\n",
    "\tname = name.replace(\".pdf_\", \"_\")\n",
    "\treturn f\"{name}.png\"\n",
    "\n",
    "\n",
    "def _scale_bbox(bbox: List[float], sx: float, sy: float, new_w: int, new_h: int) -> List[int]:\n",
    "\t\"\"\"Scale [x1, y1, x2, y2] with separate x/y factors and clamp to image bounds.\n",
    "\n",
    "\tClamps to valid pixel indices [0..new_dim-1]. Uses floor for left/top and ceil for right/bottom\n",
    "\tto better preserve coverage when converting to integer coordinates.\n",
    "\t\"\"\"\n",
    "\tx1, y1, x2, y2 = bbox\n",
    "\t# Scale as floats first\n",
    "\tnx1 = x1 * sx\n",
    "\tny1 = y1 * sy\n",
    "\tnx2 = x2 * sx\n",
    "\tny2 = y2 * sy\n",
    "\t# Ensure proper ordering\n",
    "\tleft, right = (nx1, nx2) if nx1 <= nx2 else (nx2, nx1)\n",
    "\ttop, bottom = (ny1, ny2) if ny1 <= ny2 else (ny2, ny1)\n",
    "\t# Clamp to image bounds (inclusive indices up to new_dim-1)\n",
    "\tmax_x = max(0, new_w - 1)\n",
    "\tmax_y = max(0, new_h - 1)\n",
    "\tleft = max(0.0, min(float(max_x), float(left)))\n",
    "\tright = max(0.0, min(float(max_x), float(right)))\n",
    "\ttop = max(0.0, min(float(max_y), float(top)))\n",
    "\tbottom = max(0.0, min(float(max_y), float(bottom)))\n",
    "\t# Convert to ints\n",
    "\tfrom math import floor, ceil\n",
    "\treturn [int(floor(left)), int(floor(top)), int(ceil(right)), int(ceil(bottom))]\n",
    "\n",
    "\n",
    "def resize_bboxes_for_images(\n",
    "\tjson_preds_dir: str,\n",
    "\timages_dir: str,\n",
    "\tnew_width: int,\n",
    "\tnew_height: int,\n",
    "\toutput_json_dir: Optional[str] = None,\n",
    "\toutput_images_dir: Optional[str] = None,\n",
    ") -> Dict[str, List[dict]]:\n",
    "\t\"\"\"\n",
    "\tResize bboxes in all JSON files in json_preds_dir to match a new image size.\n",
    "\n",
    "\t- Expects each JSON file to be a list of dicts with a \"bbox\": [x1, y1, x2, y2].\n",
    "\t- Matches images by converting the JSON filename to image filename:\n",
    "\t  votes_<doc>.pdf_pageN.json -> <doc>_pageN.png\n",
    "\t- Scales coordinates using the original image's size from images_dir.\n",
    "\t- Optionally writes resized JSON to output_json_dir and resized images to output_images_dir.\n",
    "\n",
    "\tReturns: dict mapping json_filename (basename) -> resized annotations (list of dicts)\n",
    "\t\"\"\"\n",
    "\tif not os.path.isdir(json_preds_dir):\n",
    "\t\traise FileNotFoundError(f\"json_preds_dir not found: {json_preds_dir}\")\n",
    "\tif not os.path.isdir(images_dir):\n",
    "\t\traise FileNotFoundError(f\"images_dir not found: {images_dir}\")\n",
    "\n",
    "\tif output_json_dir:\n",
    "\t\tos.makedirs(output_json_dir, exist_ok=True)\n",
    "\tif output_images_dir:\n",
    "\t\tos.makedirs(output_images_dir, exist_ok=True)\n",
    "\n",
    "\tresults: Dict[str, List[dict]] = {}\n",
    "\n",
    "\tjson_paths = sorted(glob.glob(os.path.join(json_preds_dir, \"*.json\")))\n",
    "\tfor json_path in json_paths:\n",
    "\t\tjson_base = os.path.basename(json_path)\n",
    "\t\timage_name = _derive_image_filename_from_json(json_base)\n",
    "\t\timage_path = os.path.join(images_dir, image_name)\n",
    "\n",
    "\t\tif not os.path.isfile(image_path):\n",
    "\t\t\t# Skip if the corresponding image is missing\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\twith Image.open(image_path) as im:\n",
    "\t\t\torig_w, orig_h = im.size\n",
    "\t\t\tif output_images_dir:\n",
    "\t\t\t\tresized_im = im.resize((new_width, new_height), resample=Image.Resampling.LANCZOS)\n",
    "\t\t\t\tresized_im.save(os.path.join(output_images_dir, image_name))\n",
    "\n",
    "\t\tsx = float(new_width) / float(orig_w)\n",
    "\t\tsy = float(new_height) / float(orig_h)\n",
    "\n",
    "\t\twith open(json_path, \"r\") as f:\n",
    "\t\t\tannotations = json.load(f)\n",
    "\n",
    "\t\tif not isinstance(annotations, list):\n",
    "\t\t\t# Expect a list of predictions; skip malformed files\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tresized_annotations: List[dict] = []\n",
    "\t\tfor ann in annotations:\n",
    "\t\t\tif not isinstance(ann, dict):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tbbox = ann.get(\"bbox\")\n",
    "\t\t\tif not bbox or not isinstance(bbox, list) or len(bbox) != 4:\n",
    "\t\t\t\tresized_annotations.append(ann)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# Detect bbox mode: normalized [0..1], pixel, or placeholder/invalid (very small ints)\n",
    "\t\t\tmode = \"pixel\"\n",
    "\t\t\tif all(isinstance(v, (int, float)) for v in bbox):\n",
    "\t\t\t\tmin_v = float(min(bbox))\n",
    "\t\t\t\tmax_v = float(max(bbox))\n",
    "\t\t\t\tif 0.0 <= min_v and max_v <= 1.0:\n",
    "\t\t\t\t\tmode = \"normalized\"\n",
    "\t\t\t\telif max_v <= 3.0:\n",
    "\t\t\t\t\tmode = \"invalid\"  # likely placeholder, not pixels\n",
    "\t\t\t# Compute new bbox based on mode\n",
    "\t\t\tif mode == \"normalized\":\n",
    "\t\t\t\tnx1 = bbox[0] * new_width\n",
    "\t\t\t\tny1 = bbox[1] * new_height\n",
    "\t\t\t\tnx2 = bbox[2] * new_width\n",
    "\t\t\t\tny2 = bbox[3] * new_height\n",
    "\t\t\t\tnew_bbox = _scale_bbox([nx1, ny1, nx2, ny2], 1.0, 1.0, new_width, new_height)\n",
    "\t\t\telif mode == \"pixel\":\n",
    "\t\t\t\tnew_bbox = _scale_bbox(bbox, sx, sy, new_width, new_height)\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Keep placeholder/invalid bbox as-is (0/1/2 values); cannot scale meaningfully\n",
    "\t\t\t\tnew_bbox = bbox\n",
    "\t\t\tnew_ann = dict(ann)\n",
    "\t\t\tnew_ann[\"bbox\"] = new_bbox\n",
    "\t\t\tresized_annotations.append(new_ann)\n",
    "\n",
    "\t\tresults[json_base] = resized_annotations\n",
    "\n",
    "\t\t# Write resized annotations back to the same file by default\n",
    "\t\ttarget_json_path = os.path.join(output_json_dir, json_base) if output_json_dir else json_path\n",
    "\t\twith open(target_json_path, \"w\") as f_out:\n",
    "\t\t\tjson.dump(resized_annotations, f_out, indent=2)\n",
    "\n",
    "\treturn results\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "out = resize_bboxes_for_images(\n",
    "\tjson_preds_dir,\n",
    "\timages_dir,\n",
    "\t840,\n",
    "\t840,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f94d7adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0a32ce11-7ed9-14ee-8856-6a1edfad9ff3_page2.png': {'orig_w': 612,\n",
       "  'orig_h': 792,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " '456300-sept-17-23-2012-11953-13474707086771-_-pdf_page1.png': {'orig_w': 616,\n",
       "  'orig_h': 790,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'e038716a-f9a1-2ab5-e72b-eb2f00f26981_page1.png': {'orig_w': 792,\n",
       "  'orig_h': 612,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'e8d41204-64eb-9f4b-608e-5593933aca41_page1.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'e8d41204-64eb-9f4b-608e-5593933aca41_page4.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'e910d31f-0c5a-5041-1a4d-1f1b39606992_page1.png': {'orig_w': 792,\n",
       "  'orig_h': 612,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'eabf486e-2ff6-c060-68b7-fcf5363bde66_page1.png': {'orig_w': 612,\n",
       "  'orig_h': 792,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'eabf486e-2ff6-c060-68b7-fcf5363bde66_page2.png': {'orig_w': 612,\n",
       "  'orig_h': 792,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'eabf486e-2ff6-c060-68b7-fcf5363bde66_page3.png': {'orig_w': 612,\n",
       "  'orig_h': 792,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'ee19ec76-3531-254f-c21f-869b6cf0916c_page1.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'ee19ec76-3531-254f-c21f-869b6cf0916c_page2.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'ef640e66-1f79-701f-61d7-e968acb9e3fc_page1.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'ef640e66-1f79-701f-61d7-e968acb9e3fc_page2.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'efca8764-0dfb-3f1c-beb9-f629991435bb_page1.png': {'orig_w': 842,\n",
       "  'orig_h': 595,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'efca8764-0dfb-3f1c-beb9-f629991435bb_page2.png': {'orig_w': 842,\n",
       "  'orig_h': 595,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'eff55361-0e39-53a1-da0b-a337a361b66b_page1.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'eff55361-0e39-53a1-da0b-a337a361b66b_page2.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'eff55361-0e39-53a1-da0b-a337a361b66b_page3.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'eff55361-0e39-53a1-da0b-a337a361b66b_page4.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page1.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page2.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page3.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page1.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page2.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page3.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f5a1056c-ac79-aac8-6099-87821a840150_page1.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f7635eed-5555-27b6-780f-8386863b25ca_page1.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f7635eed-5555-27b6-780f-8386863b25ca_page2.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f7635eed-5555-27b6-780f-8386863b25ca_page3.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f9a59888-b508-9792-d356-1d36de82c212_page1.png': {'orig_w': 2263,\n",
       "  'orig_h': 1749,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'f9a59888-b508-9792-d356-1d36de82c212_page2.png': {'orig_w': 2263,\n",
       "  'orig_h': 1749,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'faa55a77-9090-22ac-fe9b-32ab3f026300_page1.png': {'orig_w': 842,\n",
       "  'orig_h': 595,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'fdf168ea-c840-1465-710a-762427b285c3_page1.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840},\n",
       " 'ff9c72fa-8267-5701-5492-e8cbf336e101_page2.png': {'orig_w': 612,\n",
       "  'orig_h': 793,\n",
       "  'new_w': 840,\n",
       "  'new_h': 840}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def resize_images_in_dir(\n",
    "\timages_dir: str,\n",
    "\tnew_width: int,\n",
    "\tnew_height: int,\n",
    "\toutput_dir: str,\n",
    ") -> Dict[str, Dict[str, int]]:\n",
    "\t\"\"\"\n",
    "\tResize all images in images_dir to (new_width, new_height) and save into output_dir.\n",
    "\n",
    "\tSupported extensions: .png, .jpg, .jpeg, .tif, .tiff, .webp\n",
    "\tReturns: dict mapping filename -> {\"orig_w\", \"orig_h\", \"new_w\", \"new_h\"}\n",
    "\t\"\"\"\n",
    "\tif not os.path.isdir(images_dir):\n",
    "\t\traise FileNotFoundError(f\"images_dir not found: {images_dir}\")\n",
    "\tos.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\tresults: Dict[str, Dict[str, int]] = {}\n",
    "\texts = (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.tif\", \"*.tiff\", \"*.webp\")\n",
    "\timage_paths: List[str] = []\n",
    "\tfor ext in exts:\n",
    "\t\timage_paths.extend(sorted(glob.glob(os.path.join(images_dir, ext))))\n",
    "\n",
    "\tfor image_path in image_paths:\n",
    "\t\tfilename = os.path.basename(image_path)\n",
    "\t\ttry:\n",
    "\t\t\twith Image.open(image_path) as im:\n",
    "\t\t\t\torig_w, orig_h = im.size\n",
    "\t\t\t\tresized_im = im.resize((new_width, new_height), resample=Image.Resampling.LANCZOS)\n",
    "\t\t\t\tresized_im.save(os.path.join(output_dir, filename))\n",
    "\t\t\t\tresults[filename] = {\"orig_w\": orig_w, \"orig_h\": orig_h, \"new_w\": new_width, \"new_h\": new_height}\n",
    "\t\texcept Exception:\n",
    "\t\t\t# Skip files Pillow can't open\n",
    "\t\t\tcontinue\n",
    "\n",
    "\treturn results\n",
    "\n",
    "resize_images_in_dir(\n",
    "    images_dir=\"/Volumes/MyDataDrive/thesis/code-2/src/labelrix/ad-buy-form/test-images\",\n",
    "    new_width=840,\n",
    "    new_height=840,\n",
    "    output_dir=\"/Volumes/MyDataDrive/thesis/code-2/src/labelrix/ad-buy-form/test-images-resized-840\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
