{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0512c3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 9 annotations for 2fac4856-ff9c72fa-8267-5701-5492-e8cbf336e101_page2.png -> ad-buy-form-test-labels/2fac4856-ff9c72fa-8267-5701-5492-e8cbf336e101_page2.json\n",
      "Saved 27 annotations for 981b4837-fdf168ea-c840-1465-710a-762427b285c3_page1.png -> ad-buy-form-test-labels/981b4837-fdf168ea-c840-1465-710a-762427b285c3_page1.json\n",
      "Saved 15 annotations for 423f9ea6-faa55a77-9090-22ac-fe9b-32ab3f026300_page1.png -> ad-buy-form-test-labels/423f9ea6-faa55a77-9090-22ac-fe9b-32ab3f026300_page1.json\n",
      "Saved 24 annotations for 71662f51-f7635eed-5555-27b6-780f-8386863b25ca_page3.png -> ad-buy-form-test-labels/71662f51-f7635eed-5555-27b6-780f-8386863b25ca_page3.json\n",
      "Saved 15 annotations for 156320b0-f9a59888-b508-9792-d356-1d36de82c212_page2.png -> ad-buy-form-test-labels/156320b0-f9a59888-b508-9792-d356-1d36de82c212_page2.json\n",
      "Saved 26 annotations for 25fab5c0-f9a59888-b508-9792-d356-1d36de82c212_page1.png -> ad-buy-form-test-labels/25fab5c0-f9a59888-b508-9792-d356-1d36de82c212_page1.json\n",
      "Saved 38 annotations for 1eb6480c-f7635eed-5555-27b6-780f-8386863b25ca_page2.png -> ad-buy-form-test-labels/1eb6480c-f7635eed-5555-27b6-780f-8386863b25ca_page2.json\n",
      "Saved 38 annotations for ad7b330a-f7635eed-5555-27b6-780f-8386863b25ca_page1.png -> ad-buy-form-test-labels/ad7b330a-f7635eed-5555-27b6-780f-8386863b25ca_page1.json\n",
      "Saved 25 annotations for bd818d25-f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page3.png -> ad-buy-form-test-labels/bd818d25-f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page3.json\n",
      "Saved 40 annotations for fdc829c8-f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page2.png -> ad-buy-form-test-labels/fdc829c8-f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page2.json\n",
      "Saved 32 annotations for da435e02-f5a1056c-ac79-aac8-6099-87821a840150_page1.png -> ad-buy-form-test-labels/da435e02-f5a1056c-ac79-aac8-6099-87821a840150_page1.json\n",
      "Saved 41 annotations for 0c6862cc-f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page1.png -> ad-buy-form-test-labels/0c6862cc-f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page1.json\n",
      "Saved 9 annotations for d79923b0-f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page3.png -> ad-buy-form-test-labels/d79923b0-f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page3.json\n",
      "Saved 52 annotations for cc5e7e52-f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page2.png -> ad-buy-form-test-labels/cc5e7e52-f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page2.json\n",
      "Saved 45 annotations for 2c197804-f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page1.png -> ad-buy-form-test-labels/2c197804-f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page1.json\n",
      "Saved 10 annotations for 7ee538f4-eff55361-0e39-53a1-da0b-a337a361b66b_page4.png -> ad-buy-form-test-labels/7ee538f4-eff55361-0e39-53a1-da0b-a337a361b66b_page4.json\n",
      "Saved 44 annotations for 15294724-eff55361-0e39-53a1-da0b-a337a361b66b_page3.png -> ad-buy-form-test-labels/15294724-eff55361-0e39-53a1-da0b-a337a361b66b_page3.json\n",
      "Saved 44 annotations for 7cdb0698-eff55361-0e39-53a1-da0b-a337a361b66b_page2.png -> ad-buy-form-test-labels/7cdb0698-eff55361-0e39-53a1-da0b-a337a361b66b_page2.json\n",
      "Saved 41 annotations for 83b0f41f-eff55361-0e39-53a1-da0b-a337a361b66b_page1.png -> ad-buy-form-test-labels/83b0f41f-eff55361-0e39-53a1-da0b-a337a361b66b_page1.json\n",
      "Saved 18 annotations for 163d14b9-efca8764-0dfb-3f1c-beb9-f629991435bb_page2.png -> ad-buy-form-test-labels/163d14b9-efca8764-0dfb-3f1c-beb9-f629991435bb_page2.json\n",
      "Saved 14 annotations for d37decd2-efca8764-0dfb-3f1c-beb9-f629991435bb_page1.png -> ad-buy-form-test-labels/d37decd2-efca8764-0dfb-3f1c-beb9-f629991435bb_page1.json\n",
      "Saved 38 annotations for 3aa8ab38-ef640e66-1f79-701f-61d7-e968acb9e3fc_page2.png -> ad-buy-form-test-labels/3aa8ab38-ef640e66-1f79-701f-61d7-e968acb9e3fc_page2.json\n",
      "Saved 17 annotations for d1d1c7c8-ef640e66-1f79-701f-61d7-e968acb9e3fc_page1.png -> ad-buy-form-test-labels/d1d1c7c8-ef640e66-1f79-701f-61d7-e968acb9e3fc_page1.json\n",
      "Saved 6 annotations for f3e7f291-ee19ec76-3531-254f-c21f-869b6cf0916c_page2.png -> ad-buy-form-test-labels/f3e7f291-ee19ec76-3531-254f-c21f-869b6cf0916c_page2.json\n",
      "Saved 13 annotations for c9930e97-ee19ec76-3531-254f-c21f-869b6cf0916c_page1.png -> ad-buy-form-test-labels/c9930e97-ee19ec76-3531-254f-c21f-869b6cf0916c_page1.json\n",
      "Saved 19 annotations for 6d7ab39d-eabf486e-2ff6-c060-68b7-fcf5363bde66_page3.png -> ad-buy-form-test-labels/6d7ab39d-eabf486e-2ff6-c060-68b7-fcf5363bde66_page3.json\n",
      "Saved 33 annotations for ae8deff5-eabf486e-2ff6-c060-68b7-fcf5363bde66_page2.png -> ad-buy-form-test-labels/ae8deff5-eabf486e-2ff6-c060-68b7-fcf5363bde66_page2.json\n",
      "Saved 33 annotations for 4827ce5e-eabf486e-2ff6-c060-68b7-fcf5363bde66_page1.png -> ad-buy-form-test-labels/4827ce5e-eabf486e-2ff6-c060-68b7-fcf5363bde66_page1.json\n",
      "Saved 19 annotations for 591b2144-e910d31f-0c5a-5041-1a4d-1f1b39606992_page1.png -> ad-buy-form-test-labels/591b2144-e910d31f-0c5a-5041-1a4d-1f1b39606992_page1.json\n",
      "Saved 35 annotations for 4043cd85-e8d41204-64eb-9f4b-608e-5593933aca41_page4.png -> ad-buy-form-test-labels/4043cd85-e8d41204-64eb-9f4b-608e-5593933aca41_page4.json\n",
      "Saved 19 annotations for 5a5fe56b-e8d41204-64eb-9f4b-608e-5593933aca41_page1.png -> ad-buy-form-test-labels/5a5fe56b-e8d41204-64eb-9f4b-608e-5593933aca41_page1.json\n",
      "Saved 37 annotations for d36c640f-e038716a-f9a1-2ab5-e72b-eb2f00f26981_page1.png -> ad-buy-form-test-labels/d36c640f-e038716a-f9a1-2ab5-e72b-eb2f00f26981_page1.json\n",
      "Saved 11 annotations for bc0e9c35-456300-sept-17-23-2012-11953-13474707086771-_-pdf_page1.png -> ad-buy-form-test-labels/bc0e9c35-456300-sept-17-23-2012-11953-13474707086771-_-pdf_page1.json\n",
      "Saved 14 annotations for f5dac1c2-0a32ce11-7ed9-14ee-8856-6a1edfad9ff3_page2.png -> ad-buy-form-test-labels/f5dac1c2-0a32ce11-7ed9-14ee-8856-6a1edfad9ff3_page2.json\n",
      "\n",
      "Total: Saved labels for 34 files in 'ad-buy-form-test-labels' directory\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Make a flat list of consolidated annotations using **ID-only** pairing:\n",
    "[{\"id\": \"...\", \"type\": \"...\", \"value\": \"...\", \"bbox\": [l,t,r,b]}]\n",
    "\n",
    "- Uses rectanglelabels for (type + bbox) and textarea for (value)\n",
    "- Pairs ONLY when result IDs are equal (no IoU fallback)\n",
    "- Converts percentage coords to pixel bbox\n",
    "- Optional: --with-file-name adds \"file_name\" to each item\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "def _pct_to_px_bbox(x: float, y: float, w: float, h: float, W: int, H: int) -> List[int]:\n",
    "    l = round(x * W / 100.0)\n",
    "    t = round(y * H / 100.0)\n",
    "    r = round((x + w) * W / 100.0)\n",
    "    b = round((y + h) * H / 100.0)\n",
    "    # clamp\n",
    "    l = max(0, min(l, W)); r = max(0, min(r, W))\n",
    "    t = max(0, min(t, H)); b = max(0, min(b, H))\n",
    "    return [l, t, r, b]\n",
    "\n",
    "def _resize_bbox_to_840(bbox: List[int], original_width: int, original_height: int, target_size: int = 840) -> List[int]:\n",
    "    \"\"\"\n",
    "    Resize bbox coordinates from original dimensions to target_size x target_size.\n",
    "    \n",
    "    Args:\n",
    "        bbox: [left, top, right, bottom] in original image coordinates\n",
    "        original_width: Original image width\n",
    "        original_height: Original image height  \n",
    "        target_size: Target square size (default 840)\n",
    "        \n",
    "    Returns:\n",
    "        Resized bbox [left, top, right, bottom] in target coordinates\n",
    "    \"\"\"\n",
    "    l, t, r, b = bbox\n",
    "    \n",
    "    # Calculate scale factors\n",
    "    scale_x = target_size / original_width\n",
    "    scale_y = target_size / original_height\n",
    "    \n",
    "    # Apply scaling\n",
    "    new_l = round(l * scale_x)\n",
    "    new_t = round(t * scale_y)\n",
    "    new_r = round(r * scale_x)\n",
    "    new_b = round(b * scale_y)\n",
    "    \n",
    "    # Clamp to target dimensions\n",
    "    new_l = max(0, min(new_l, target_size))\n",
    "    new_t = max(0, min(new_t, target_size))\n",
    "    new_r = max(0, min(new_r, target_size))\n",
    "    new_b = max(0, min(new_b, target_size))\n",
    "    \n",
    "    return [new_l, new_t, new_r, new_b]\n",
    "\n",
    "def _basename_from_task(task: Dict[str, Any]) -> str:\n",
    "    data = task.get(\"data\", {}) or {}\n",
    "    for key in (\"ocr\", \"image\", \"url\"):\n",
    "        v = data.get(key)\n",
    "        if isinstance(v, str) and v:\n",
    "            return os.path.basename(v)\n",
    "    v = task.get(\"file_upload\")\n",
    "    if isinstance(v, str) and v:\n",
    "        return os.path.basename(v)\n",
    "    return f\"task_{task.get('id','unknown')}\"\n",
    "\n",
    "def consolidate_flat_id_only(ls_export_path: str, include_filename: bool = False) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Read a Label Studio export JSON and return a flat list:\n",
    "    [{\"id\",\"type\",\"value\",\"bbox\"}]  (+ \"file_name\" if include_filename=True)\n",
    "    \"\"\"\n",
    "    with open(ls_export_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    tasks = data if isinstance(data, list) else data.get(\"tasks\") or data.get(\"results\") or []\n",
    "    flat: List[Dict[str, Any]] = []\n",
    "\n",
    "    for task in tasks:\n",
    "        file_name = _basename_from_task(task)\n",
    "\n",
    "        for ann in (task.get(\"annotations\") or []):\n",
    "            rect_by_id: Dict[str, Dict[str, Any]] = {}\n",
    "            text_by_id: Dict[str, List[str]] = {}\n",
    "\n",
    "            for r in (ann.get(\"result\") or []):\n",
    "                r_id = r.get(\"id\") or \"\"\n",
    "                if not r_id:\n",
    "                    continue\n",
    "\n",
    "                v = r.get(\"value\") or {}\n",
    "                W = r.get(\"original_width\"); H = r.get(\"original_height\")\n",
    "                x, y, w, h = v.get(\"x\"), v.get(\"y\"), v.get(\"width\"), v.get(\"height\")\n",
    "\n",
    "                # need dimensions + geometry\n",
    "                if not all(isinstance(t, (int, float)) for t in (W, H, x, y, w, h)):\n",
    "                    continue\n",
    "\n",
    "                bbox = _pct_to_px_bbox(float(x), float(y), float(w), float(h), int(W), int(H))\n",
    "                # Resize bbox to 840x840\n",
    "                resized_bbox = _resize_bbox_to_840(bbox, int(W), int(H))\n",
    "\n",
    "                if r.get(\"type\") == \"rectanglelabels\":\n",
    "                    labels = v.get(\"rectanglelabels\") or []\n",
    "                    if labels:\n",
    "                        rect_by_id[r_id] = {\"label\": str(labels[0]), \"bbox\": resized_bbox}\n",
    "\n",
    "                elif r.get(\"type\") == \"textarea\":\n",
    "                    txt_list = v.get(\"text\") or []\n",
    "                    text = \" \".join(map(str, txt_list)) if isinstance(txt_list, list) else str(txt_list)\n",
    "                    text_by_id.setdefault(r_id, []).append(text)\n",
    "\n",
    "            # emit only when ids match on both sides\n",
    "            for r_id, rect in rect_by_id.items():\n",
    "                if r_id in text_by_id:\n",
    "                    item = {\n",
    "                        \"id\": r_id,\n",
    "                        \"type\": rect[\"label\"],\n",
    "                        \"value\": \" \".join(text_by_id[r_id]).strip(),\n",
    "                        \"bbox\": rect[\"bbox\"],\n",
    "                    }\n",
    "                    if include_filename:\n",
    "                        item[\"file_name\"] = file_name\n",
    "                    flat.append(item)\n",
    "\n",
    "    return flat\n",
    "\n",
    "def consolidate_by_filename(ls_export_path: str) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Read a Label Studio export JSON and return a dictionary grouped by filename:\n",
    "    {\"filename.ext\": [{\"id\",\"type\",\"value\",\"bbox\"}, ...]}\n",
    "    \"\"\"\n",
    "    with open(ls_export_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    tasks = data if isinstance(data, list) else data.get(\"tasks\") or data.get(\"results\") or []\n",
    "    by_filename: Dict[str, List[Dict[str, Any]]] = {}\n",
    "\n",
    "    for task in tasks:\n",
    "        file_name = _basename_from_task(task)\n",
    "\n",
    "        for ann in (task.get(\"annotations\") or []):\n",
    "            rect_by_id: Dict[str, Dict[str, Any]] = {}\n",
    "            text_by_id: Dict[str, List[str]] = {}\n",
    "\n",
    "            for r in (ann.get(\"result\") or []):\n",
    "                r_id = r.get(\"id\") or \"\"\n",
    "                if not r_id:\n",
    "                    continue\n",
    "\n",
    "                v = r.get(\"value\") or {}\n",
    "                W = r.get(\"original_width\"); H = r.get(\"original_height\")\n",
    "                x, y, w, h = v.get(\"x\"), v.get(\"y\"), v.get(\"width\"), v.get(\"height\")\n",
    "\n",
    "                # need dimensions + geometry\n",
    "                if not all(isinstance(t, (int, float)) for t in (W, H, x, y, w, h)):\n",
    "                    continue\n",
    "\n",
    "                bbox = _pct_to_px_bbox(float(x), float(y), float(w), float(h), int(W), int(H))\n",
    "                # Resize bbox to 840x840\n",
    "                resized_bbox = _resize_bbox_to_840(bbox, int(W), int(H))\n",
    "\n",
    "                if r.get(\"type\") == \"rectanglelabels\":\n",
    "                    labels = v.get(\"rectanglelabels\") or []\n",
    "                    if labels:\n",
    "                        rect_by_id[r_id] = {\"label\": str(labels[0]), \"bbox\": resized_bbox}\n",
    "\n",
    "                elif r.get(\"type\") == \"textarea\":\n",
    "                    txt_list = v.get(\"text\") or []\n",
    "                    text = \" \".join(map(str, txt_list)) if isinstance(txt_list, list) else str(txt_list)\n",
    "                    text_by_id.setdefault(r_id, []).append(text)\n",
    "\n",
    "            # emit only when ids match on both sides\n",
    "            file_annotations = []\n",
    "            for r_id, rect in rect_by_id.items():\n",
    "                if r_id in text_by_id:\n",
    "                    item = {\n",
    "                        \"id\": r_id,\n",
    "                        \"type\": rect[\"label\"],\n",
    "                        \"value\": \" \".join(text_by_id[r_id]).strip(),\n",
    "                        \"bbox\": rect[\"bbox\"],\n",
    "                    }\n",
    "                    file_annotations.append(item)\n",
    "            \n",
    "            # Add annotations to the file's list\n",
    "            if file_annotations:\n",
    "                if file_name not in by_filename:\n",
    "                    by_filename[file_name] = []\n",
    "                by_filename[file_name].extend(file_annotations)\n",
    "\n",
    "    return by_filename\n",
    "\n",
    "def save_labels_by_file(ls_export_path: str, output_dir: str = \"labels_output\") -> None:\n",
    "    \"\"\"\n",
    "    Extract labels from Label Studio export and save each file's labels as separate JSON files.\n",
    "    \"\"\"\n",
    "    labels_by_file = consolidate_by_filename(ls_export_path)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    saved_count = 0\n",
    "    for file_name, annotations in labels_by_file.items():\n",
    "        # Remove extension and add .json\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        output_file = os.path.join(output_dir, f\"{base_name}.json\")\n",
    "        \n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(annotations, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"Saved {len(annotations)} annotations for {file_name} -> {output_file}\")\n",
    "        saved_count += 1\n",
    "    \n",
    "    print(f\"\\nTotal: Saved labels for {saved_count} files in '{output_dir}' directory\")\n",
    "\n",
    "path = \"/Users/vishnuprasad/Downloads/export_179167_project-179167-at-2025-08-26-01-58-2cd3a2e9.json\"\n",
    "\n",
    "# Option 1: Save labels for each file separately (NEW APPROACH)\n",
    "save_labels_by_file(path, output_dir=\"ad-buy-form-test-labels\")\n",
    "\n",
    "# # Option 2: Keep the original flat list approach (ORIGINAL APPROACH)\n",
    "# out = consolidate_flat_id_only(path, include_filename=True)\n",
    "# with open(\"test-adbuy-34-samples-with-filename.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(out, f, ensure_ascii=False, indent=2)\n",
    "# print(f\"Wrote {len(out)} items to combined file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d41137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 JSON files in /Volumes/MyDataDrive/thesis/code-2/src/labelrix/ad-buy-form-test-labels\n",
      "Processed 0c6862cc-f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page1: 41 labels\n",
      "Processed 15294724-eff55361-0e39-53a1-da0b-a337a361b66b_page3: 44 labels\n",
      "Processed 156320b0-f9a59888-b508-9792-d356-1d36de82c212_page2: 15 labels\n",
      "Processed 163d14b9-efca8764-0dfb-3f1c-beb9-f629991435bb_page2: 18 labels\n",
      "Processed 1eb6480c-f7635eed-5555-27b6-780f-8386863b25ca_page2: 38 labels\n",
      "Processed 25fab5c0-f9a59888-b508-9792-d356-1d36de82c212_page1: 26 labels\n",
      "Processed 2c197804-f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page1: 45 labels\n",
      "Processed 2fac4856-ff9c72fa-8267-5701-5492-e8cbf336e101_page2: 9 labels\n",
      "Processed 3aa8ab38-ef640e66-1f79-701f-61d7-e968acb9e3fc_page2: 38 labels\n",
      "Processed 4043cd85-e8d41204-64eb-9f4b-608e-5593933aca41_page4: 35 labels\n",
      "Processed 423f9ea6-faa55a77-9090-22ac-fe9b-32ab3f026300_page1: 15 labels\n",
      "Processed 4827ce5e-eabf486e-2ff6-c060-68b7-fcf5363bde66_page1: 33 labels\n",
      "Processed 591b2144-e910d31f-0c5a-5041-1a4d-1f1b39606992_page1: 19 labels\n",
      "Processed 5a5fe56b-e8d41204-64eb-9f4b-608e-5593933aca41_page1: 19 labels\n",
      "Processed 6d7ab39d-eabf486e-2ff6-c060-68b7-fcf5363bde66_page3: 19 labels\n",
      "Processed 71662f51-f7635eed-5555-27b6-780f-8386863b25ca_page3: 24 labels\n",
      "Processed 7cdb0698-eff55361-0e39-53a1-da0b-a337a361b66b_page2: 44 labels\n",
      "Processed 7ee538f4-eff55361-0e39-53a1-da0b-a337a361b66b_page4: 10 labels\n",
      "Processed 83b0f41f-eff55361-0e39-53a1-da0b-a337a361b66b_page1: 41 labels\n",
      "Processed 981b4837-fdf168ea-c840-1465-710a-762427b285c3_page1: 27 labels\n",
      "Processed ad7b330a-f7635eed-5555-27b6-780f-8386863b25ca_page1: 38 labels\n",
      "Processed ae8deff5-eabf486e-2ff6-c060-68b7-fcf5363bde66_page2: 33 labels\n",
      "Processed bc0e9c35-456300-sept-17-23-2012-11953-13474707086771-_-pdf_page1: 11 labels\n",
      "Processed bd818d25-f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page3: 25 labels\n",
      "Processed c9930e97-ee19ec76-3531-254f-c21f-869b6cf0916c_page1: 13 labels\n",
      "Processed cc5e7e52-f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page2: 52 labels\n",
      "Processed d1d1c7c8-ef640e66-1f79-701f-61d7-e968acb9e3fc_page1: 17 labels\n",
      "Processed d36c640f-e038716a-f9a1-2ab5-e72b-eb2f00f26981_page1: 37 labels\n",
      "Processed d37decd2-efca8764-0dfb-3f1c-beb9-f629991435bb_page1: 14 labels\n",
      "Processed d79923b0-f21fcdd1-214c-c145-29cc-362e0b0ef1e3_page3: 9 labels\n",
      "Processed da435e02-f5a1056c-ac79-aac8-6099-87821a840150_page1: 32 labels\n",
      "Processed f3e7f291-ee19ec76-3531-254f-c21f-869b6cf0916c_page2: 6 labels\n",
      "Processed f5dac1c2-0a32ce11-7ed9-14ee-8856-6a1edfad9ff3_page2: 14 labels\n",
      "Processed fdc829c8-f56e2fc1-7f41-68e3-bfe5-06176b9a2e8a_page2: 40 labels\n",
      "\n",
      "Saved consolidated data to /Volumes/MyDataDrive/thesis/code-2/src/labelrix/ad-buy-form-testset-labels-consolidated.json\n",
      "Total files: 34\n",
      "Total labels: 901\n"
     ]
    }
   ],
   "source": [
    "def create_consolidated_test_data(labels_dir: str, output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Convert individual label files to consolidated test data format.\n",
    "    \n",
    "    Format: [{\"file_name\": \"...\", \"labels\": [{\"entity_type\": \"...\", \"value\": \"...\", \"bbox\": [...]}]}]\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    consolidated_data = []\n",
    "    \n",
    "    # Read all JSON files in the labels directory\n",
    "    labels_path = Path(labels_dir)\n",
    "    if not labels_path.exists():\n",
    "        print(f\"Error: Directory {labels_dir} does not exist\")\n",
    "        return\n",
    "    \n",
    "    json_files = list(labels_path.glob(\"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files in {labels_dir}\")\n",
    "    \n",
    "    for json_file in sorted(json_files):\n",
    "        file_name = json_file.stem  # filename without extension\n",
    "        \n",
    "        try:\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                annotations = json.load(f)\n",
    "            \n",
    "            # Convert format: \"type\" -> \"entity_type\", remove \"id\"\n",
    "            labels = []\n",
    "            for ann in annotations:\n",
    "                if isinstance(ann, dict) and all(key in ann for key in [\"type\", \"value\", \"bbox\"]):\n",
    "                    labels.append({\n",
    "                        \"entity_type\": ann[\"type\"],\n",
    "                        \"value\": ann[\"value\"],\n",
    "                        \"bbox\": ann[\"bbox\"]\n",
    "                    })\n",
    "            \n",
    "            if labels:  # Only add if there are valid labels\n",
    "                consolidated_data.append({\n",
    "                    \"file_name\": file_name,\n",
    "                    \"labels\": labels\n",
    "                })\n",
    "                print(f\"Processed {file_name}: {len(labels)} labels\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file}: {e}\")\n",
    "    \n",
    "    # Save consolidated data\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(consolidated_data, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"\\nSaved consolidated data to {output_file}\")\n",
    "    print(f\"Total files: {len(consolidated_data)}\")\n",
    "    print(f\"Total labels: {sum(len(item['labels']) for item in consolidated_data)}\")\n",
    "\n",
    "# Create the consolidated test data file\n",
    "labels_directory = \"/Volumes/MyDataDrive/thesis/code-2/src/labelrix/ad-buy-form-test-labels\"\n",
    "output_filename = \"/Volumes/MyDataDrive/thesis/code-2/src/labelrix/ad-buy-form-testset-labels-consolidated.json\"\n",
    "\n",
    "create_consolidated_test_data(labels_directory, output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77d2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
